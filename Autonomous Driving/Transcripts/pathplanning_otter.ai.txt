Unknown Speaker  0:01  
We are now going to get much deeper into the pathogen domain after we have just established the basis, we have here again, the one general idea of how to control a self driving car. In order to say that we you first perform some kind of sensing, then we perform some kind of planning. And then we act. And you can see on the planning that we have navigation task planning path motion planning trajectory generation, and then the acting we have how we actually can control the actuators driving by wire steering the wire, we have the trajectory control the emergency brake. So, for the next phase of the lecture, we look, we're looking at the top right part of this diagram, especially at the parven motion planning. We will refine our problem definitions, the definitions for past directories motion, we will look at the configuration space in more detail operations we can perform with it, we will look at constraints how we define them in a sense, the way we will look at properties of toppling algorithms such as correctness optimality. And then we will come to the different path planning methods that we're going to study in this lecture. And among these, they are the combinatorial methods to behaviour based methods, the random sampling methods to search based methods, more and more methods exist, you should be able to understand the differences such that, for your own problems, you can make intelligent selections. path for us defines the geometric form of emotion from start to go. It can be represented as a list of poses were posed means X and Y coordinate and orientation of the vehicle or the robot. The motion now defines the movement along the path regarding the physical laws, which can be represented with a list of control inputs. And the trajectory is the result of emotion. So, what the guy actually drives a few commands commanded in a certain way, which can be represented with a list of poses with timestamps. And going from the top to the bottom, you also often refine your, your actual actual outputs. So it could be that you say you have a start location in the goal location, and you plan a path and you say, yeah, this would be a nice path to our goal. However, it could be that this is not not something that your car can actually drive maybe, if you have the correct physics of your car represented, the only thing you can drive for something like this, just as an example. So when you want to provide input to your trajectory control, maybe you don't want to provide your first green approximation, but you want to refine the green approximation to be closer to the actual drivable path. To make it very clear, again, what is our motion planning problem that we're trying to solve? We say we have a configuration space, the area around our robot, which also contains our obstacles. And we have our constraints that tell us where are the obstacles? What are the kinematics of our robot, and we have the starting location and the goal location, then what we want to find is the path, how to drive along the path with a motion and how to execute that and follow a trajectory. If we want to discuss the correctness of our path learning algorithm, and especially its output, we could say that the path that all departmental configurations are actually valid, so that they are collision free, and that the motion between the configurations is also executable. If we want to discuss the optimality of our generated paths, we could discuss the time that it takes executed, the distance that we have to drive if it's actually safe, if it's comfortable, if its energy consumption is low, so that it's ecologically friendly. If we talk about the algorithm again, completeness of the algorithm could be discussed in terms of deciding whether a solution exists in finite amount of time versus opposed to running forever. And if a solution exists, we would like to return one solution in finite time. Let's take a look at the different methods now. Becoming tutorial methods to behaviour based methods random sampling methods and

Unknown Speaker  4:53  
the general idea of combinatorial methods could be described as directly solving the path planning problem based on the geometry of the configuration space, then the motion is calculated with regards to an explicit motion metric. So for such combinatorial methods, let's give you one example. We're using the visibility map, we want to build a road map based on a set of points whose fields of view, cover the whole configuration space. So we could add, for example, two sample points, just somewhere in the image. And from each corner point of the map, we could draw a line align to each of the sample points, as long as they do not collide with an obstacle. So we could now also, if we wanted to try to draw lines from the opposing corner here to the other point, but we would collide. And then we could cancel this line. And simultaneously, we could draw lines from each of the obstacles corners to these solid points, here, as indicated, with the red lines. And what have we got now, now we have the different elements elements here, it's almost like a map. So you could say this is the first time the second time, the third time, the fourth time, the fifth, the sixth, several times the auditor doesn't doesn't actually matter. I'm just giving unique ideas to all of these cells. And now you could make a robot plan where you say, can maybe just go from the first site to the second, and then from the second to the third, and the third to the fourth. So you get tiles that you can explore your space with by going through them. This is what it would look like if it was tidy it up a little bit, is a different variation that you could do, where you at three sample points to the space, and then you connect the three sample points, as long as they can see each other without being blocked by an obstacle. And next, you draw lines from the sample points to the corners or the dirty corners of the obstacle. As you can see here, these are these dashed lines. And with that, again, you get all these tiles that you could explore one after another. Or you could connect the corners of the map with the corners of the obstacle. Or you could combine multiple of these methods, what you're actually doing is you're performing a space decomposition. So you're building roadmap based on this basic composition, giving you nice tiles where before you adjusted continuous space, I would assume that counters approaches exist. So here are two further examples, a trapezoidal decomposition and the cylindrical decomposition with two obstacles within the space. You could also decompose the continuous space according to certain requirements on the on the results. So the Voronoi decomposition, which is also well known, is a decomposition that decomposes the configuration space with a set of objects pn, which says that each object PK has a region rk where all points are closer to this object then to any other object. So you would have here a region rk and appoint pk. And every one of the points inside this region is closer to this point, then to any of the other points. You can also see the constructor rule here that you take the three points, you connect them with straight lines, then, at the middle of the line, you do a foreigner. And then at some point his designs intersect. That's where you cut them off. And then you get these nice three areas for your three points.

Unknown Speaker  9:40  
You can place these points, for example by random sampling, and this is what it looks like with more points and if you actually calculate it, and by controlling the number of points that you throw into your space, you can make this mesh finer or coarser. So This is something that is completing the way that we can perform a set of steps in order and afterwards we are finished. And it is very easily applicable then for, for motion planning, especially with holonomic constraints. So, if you have these different tiles, and you say my robot can drive in any way at once without having to care about his orientation also, then, if you knew that, you want to get to a certain goal point, you could easily say, go from Taiwan to three, and from where Three, two to five, if one would be the start and five the goal location, it without having to care about the actual robot kinematics. So this combination to give over space to composition would make it very easy to generate a path. For example, you could also always aim for the centre points of the tiles. As I said, many variations exist, let's come to a different family of algorithms, the behaviour based methods. The general idea here is to have a reactive motion strategy for the whole configuration space, the complex behaviour as a reflex of the sophisticated environment, with simple sensing and acting schemes, and a few internal states, this will become very clear with the next explanation. This is where you say we become very clear, and then you throw lots of equations on the slide. So if you imagine that you have here, potential fields, as an example, where certain things in your configuration space, attract your robot, and certain things push your robot away, then you could, for example, say

Unknown Speaker  12:00  
here,

Unknown Speaker  12:03  
this would be your goal location. And the closer you get to it, the more strongly you want the forces to pull the robot into the centre, where this plus location here could be one which creates a field that pushes the robot away. And the closer you are to the to the plus centre, the more strongly the robot gets pushed away. So these will be potential fears. And it's evident, right, you want to have the robot be pulled into the goal location, and you want the obstacles to push the robot away. That's, that's what's meant with something that you can calculate all over your configuration space quite automatically. And it creates an almost instinctive, reactive simple behaviour screen for the robot. You can see an actual calculated example where you could imagine that there's an obstacle here in the middle. And all the space around is good for the robot to drive. But if it gets into the if it gets too close to the to the Oscar, then we'll be pushed away.

Unknown Speaker  13:30  
These potential field equations should be similar to your previous physics lectures, I guess. What you should also be familiar with from ever, medics lectures are these gradient descent methods. So if you would have calculated an artificial potential field where you're trying to reach a goal location, then at each position that you reach, you could calculate the derivatives in two different directions. And then you could basically just follow this until you reach the centre of the field. Well, and yes, the problem, right, so we have the robot in this blue location. And we have a goal location. It's clear, right? We want to drive through here. So easy. Just just calculate the resulting forces, the goal attracting us in the obstacles pushing us away. So this is the direction we want to go. These are the force vectors resulting from the obstacles. And yeah, now if this all evens out, then the robot is stuck forever. We have hit a local minimum.

Unknown Speaker  14:55  
You could of course, combine this with spacey compositional approach. So, you, again, many, many ways of doing this exists, that you could immediately come up with a simple algorithm to say, this is your gold tile. And from each of your neighbouring tiles, calculate fields that the gold tile attracts that the same time have the opposite push away. And then you can just smoothly follow your your tie in that round to the goal. Of course, now the problem that you can see here is that it's would be undefined or relatively, randomly depend on your starting position, if you would drive left or right around the the obstacle, and you wouldn't immediately take the developer off. Here are some more examples, what this can look like in practice.

Unknown Speaker  16:07  
So here's an old example from 1991 for robot, we can see that we can also have combinations of multiple simple behaviours combined with sensors. So in this case, a sonar sensor is providing sensor signals and this results in a map and this map is converted into fossils, which is then used to fill certain algorithm or everything behaviours with them a runaway behaviour and avoiding behaviour. This is what the robot in general has a year and avoiding function, a wandering function, an exploration function and such you can bring different kinds of behaviours together and trigger them depending on the conditions that you face. summarising the behaviour based methods, simple emotional strategies for the whole configuration space. However, a global guidance might be necessary in order to escape local minima auto recovery mechanisms may be necessary to get out of them. And it can be very efficient for local manoeuvres as well. So if you want to plan a path from Munich to Hamburg, you might not just do that with behavioural based methods. But if you're trying to via to avoid an obstacle, which is right next to you, then this can be a simpler way of making it smoothly random sampling methods, so we want to explore the configuration space with random samples and then create a graph and the configuration space which connects the start and the goal. probabilistic roadmaps The idea is to select random velika figuration Q, and then find the nearest neighbours mq and connect q with mq. Basically, we're putting a dot into this configuration space here. And then we're defining a sudden catching radius where we then connect all the neighbouring points in this kitchen radius. And by adding more and more samples into the space here, I could then create a finer and finer mesh. And I'm doing something similar to the to the space decomposition, where ultimately I could then use this network to plan my path and travel along the map. an explicit motion metric is required to connect the configurations this can be used as a global strategy, and then we can employ other planning methods for the local connection. And the map can be reused for multiple queries. So once we have created such graphs, and we can reuse them, well liked algorithm is rapidly exploring random trees approach RRT, which you could also check out in more details again, we sample our space, we connect the resulting samples with the nearest neighbours with valid configurations. And when we reach the goal we collect, collect

Unknown Speaker  19:40  
the shortest combination of nodes along this path and let's then our results path which you can see here in blue, from start to goal. Let's look at an example. So let's say we start from the start location. And the first sample point we get is here marked with For one, so we go a certain distance into the direction of the of the some important one, where we can, for example, say that we always go the same distance, and we check if this is gluten free and is totally fine, then we get the new saddle point to remove again, same distance to the direction tool, and check if this is gluten free and solely fine, which is good, then we get a sample point here, three, so we move a little bit to the right, we check if it's gluten free, and this is also fine, we get the sample point number four. However, when we try to move in that direction, we see that we would cloud for obstacles. So we rejected, then we get the sample point number five, so we select the, the closest point and from here we, we expand in this redirection of number five, they will trigger exclusion free, which is fine, then we get the point number six, which is down here, we select the closest neighbour, check if we can, if we expand the direction if it's gluten free, which it is, so we accepted which was a fine, we get somebody point seven, can collision free, expand the nearest neighbour up to seven, and then we expand towards eight. And we can also use a small trick. So every now and then, for example, every couple of steps, we could add the goal directly as a sample point, which would mean that we always somehow try to expand in that direction. So now we have connected and then we long the nodes select our shortest path. And we have a solution to drive this way with the RTA River. Let's look at a practical example. For lebrons. We have a car at the top left and wants to go to the go location at the bottom right.

Unknown Speaker  22:05  
Now we have found our solution path. However, as you can see why we're driving along this line, maybe here, the distance to the obstacle is it might scare the participants a little bit. And here, maybe we have more steering than would be desirable. So we have randomly searched for a path to the goal with sampling methods, we have found a path that we can drive but maybe they could be paths that would sell better in our driver system system or self driving car or they would inspire more trust and comfort within the passenger and could also be more ecologically sensible from the fuel consumption perspective. But other than that stay quite cool. summarising the tree starts from an initial configuration and grows with bias towards the goal configuration. This does not require an explicit motion metric of the configuration space. And we can apply the forward kinematics dynamics of non holonomic vehicles also in the way that we expand our trees, so we don't don't have to use a straight line connections. But instead, we can say we only expand in ways that we can also move our vehicle if wanted, easily combined. Here we see weak completeness. We can of course sample forever if we want to and then the algorithm will also run forever if no solution exists. And however it is probabilistically complete. So if we if we sample forever with infinite samples, the probability of finding an existing solution converges towards one How can we improve our path to find shorter and shorter and shorter paths to our goal with this method, of course, we can just reiterate and just run this longer and longer and longer. And at some point, we get a finer and finer and finer mesh of possible path expansions and through this we can also find shorter paths.

Unknown Speaker  24:48  
So these are very generic motion planning methods resolution probabilistically complete that we have some randomness of the results if we run this multiple times. With the Through random initialization from the same, the same scenario, then we will get different results, which can harm reproducibility. It can be inefficient with certain constraints, for example, narrow passages. And the nearest neighbour search, especially with many points available can be time consuming. How could we maybe search for our path more intelligently, if we have graph, we could have an initial note that we select the starting node. And then for each incremental step, we could take the next node of the graph and combine that with our previous node in order to say that we have now explored the connections between two nodes. And then we keep adding new node connections that we have already explored into our sets. And as soon as we reach the goal configuration, we can say that we have found one path from the start to the goal. Let's look at an example to make it more concrete. We could, for example, start in Frankfurt, and our goal is to get to Munich. Next, we could say okay, we added a monument to the track and we started we have this connection, from Frankfurt to Mannheim. And now we could add any one of these notes that can be reached with with one step from our currently explored notes. And maybe we at Castle, and we again, connect the path that we have taken there, or in the next step, we could add wurtzbach. And now we have a different node connection that we can explore, we keep just keep adding nodes until at some point, we reach our goal location. And then we know Aha, we have travelled this path and have ever reached our goals. Obviously, it is a possible solution path. Now the question is just what's an intelligent manner to explore these nodes. So one way is to say let's do depth first search. So if we start with frankford, and we have custom, then we explore this path, then maybe if next we take votes book, and then we take effort now we have closed another another branch. Then next we could go from Pittsburgh to none that to say we have explored this branch further, and then maybe from number to look at. And in finally from Munich to number two finish exploring this path, trying to go as deep as possible, as swiftly as possible branch by branch. Opposed to This will be breadth first search, for example, where you first try to explore all nodes on the same level. And then you can go one level deeper, and so on. Maybe more interesting, however, would be a best first search agresearch where we say How about we explore the most promising nodes according to a specified rule. Now you can see here that we have something like a heuristic in each of these bubbles, which tells us how far away it is actually from our goal location. So Frankfurt is to 300 kilometres away, according to some metric from Munich, and Augsburg is just 55 kilometres away from Munich. So we would assume that this is better. So out of the first three, maybe votes, Prague is one where we are already already are very close, because of 220 kilometres. And then we could again compare all our reachable nodes. And here we have one way if we go there, we already have only 150 kilometres, and from here, we can directly reach Munich. Let's enter the realm of heuristics. Consider that we would have a Eucharistic cost Ah, the estimated cost to reach the goal, we would have an actual cost stream, the sum of the edge weight in our graph from the start node, and we would have the total cost F, the sum of the ristic costs and actual costs. So you can see here that for f, h and G just get added to each other. And now what we want to do is to explore the node with the minimum total cost if

Unknown Speaker  29:14  
you can see here that for the node Frankfurt, we would have a touristic cost of 300. And if it's our starting cost, a note then the actual cost to get a zero because we already started, so the node would have 300 is a combined cost. Now if we would be in Mannheim, then from Anaheim we have a ristic cost an estimated cost to reach our goal of Munich of 270 kilometres, but we also think that we need to travel at four kilometres to get there. So the cost of Mannheim would be 270 plus 84. And through this we can calculate the the total cost F for each one of these nodes and then we can always choose to explore The next one that has those costs. And if we follow this principle, this naturally leads us to the a star search algorithm, which I also recommend you check out on your own in your own speed. The principle is very similar to what we discussed before. We have notes. Now the notes are associated with juristic costs, we have a set that we have, that we, that we that holds all the notes that are still waiting for expansion. And we have another set a closed set, which was all the nodes that we have already visited. And now we always travel to new nodes, we start our path, we compute and compare the actual costs. And once we have found the goal, then we can just backtrack, backtrack to the sort of parents and we know our social path. Practice this could look like this. So we have an open set of nodes that we can explore in the closed set of nodes that we have already explored. If we start in Frankfurt, then first Mannheim verse book and Castle, it could be saved in the Explorer set, Salzburg would have the lowest total costs. And this would then add no back end effort into the Explorer set. Next month, I'm could have to those costs which would add to Castle into the Explorer will set and then No, that could be the lowest and from nobec, we can directly directly reach number concluding our algorithm where we can then backtrack our solution path.

Unknown Speaker  31:47  
We have two

Unknown Speaker  31:48  
conditions for the ASR search the admissible conditional in the monotone condition, which result in two nice properties. If we make sure that our eurocity fulfils these conditions for the admissible condition, we can achieve it that the ASR is optimally efficient when the risk is admissible. That means it takes the minimum number of nodes to find the result. And for the monitoring condition. If it's fulfilled, then each node only needs to be evaluated once for the admissible condition. This means that the ristic estimation is all should be optimistic and not conservative. So if you ever start location, Frankfurt and go location, Munich, maybe you would have to drive around some highway curves where if you would take for the heuristic, the direct air distance, you would always be have an optimistic estimate, which would be fine. And then for the monitoring condition, it just says that for your node x and your node x wire, your ristic costs should be smaller or equal to the sum of the actual costs of between x and y, and the ristic cost y. What did we do when we said we take the direct aeroplane distance from Frankfurt to Munich, we relaxed some of the constraints, we relaxed the constraint that we actually have to follow the road. This app does create an optimistic Eucharistic we could also have ignored obstacles or ignored kinematic constraints.

Unknown Speaker  33:25  
And however, finding the best heuristic is as difficult as the search problem

Unknown Speaker  33:31  
itself. So just because your your ristic is optimistic, that doesn't mean that you will actually like the resulting path. We also had all these conditions of making a path save making the path comfortable making it ecologically promising. And urist ik could become significantly longer than what we have discussed so far. Also more computationally expensive to execute. And you could have multiple USB sticks that you then combine. So how do we deal with a continuous configuration space after we discussed all these Frankfurt and Munich notes, of course, we could just discretize our space. For example, with the A we've just creating some here, just overlaying a grid or with the space, the composition approaches that we had earlier. And now you could say, Okay, I start with this node, and then I can explore this one, and then I can explore that one and then maybe that one, so you get some kind of path to your goal. And afterwards, you can try to smooth it when you're when you're driving. It. There are lots of variations here and lots of different ways that you could implement this. So you see in the first variation here that each path goes directly through the centre of one of these cells were here for the fealty star, you travel along the, the, the edges of the cells as well. Or you could have an hybrid a star approach, where you consider the, the, the kinematics of the vehicle as well while making your path. So we are trying to map a continuous configuration to discrete grit. primitive motions would be available where we allow only different combinations of control inputs. Or we could use different combinations of Euro sticks, where one of our euro sticks, for example, could be a non holonomic distance without obstacles. To make it optimistic. The other one could be a grid based distance, including the obstacles in them, we could be combining the courses together. Let's look at an example of a hybrid a Star Search.

Unknown Speaker  36:29  
So it's very visible that this lead to different results than the RT algorithm previously, for much more direct exploration. However, this urist ik still leads to undesired steering effects like you. And it might still be driving quite narrowly around corners. So let's take it one step further and performance eristic search with space exploration. Now we have used these circles to explore in a first iteration, the big green circles in the middle. And afterwards, we've done the path through the circles guided by them. And you can see that with these small improvements, the methods, we now have some some some nice steering behaviour, we do not have many unnecessary steering commands, and also keep sensible distances to the to the corners. Here are some additional ideas of what you could include in cost functions, you could, besides the path length also have the distance to obstacles as an indicator for safety. Although this can be tricky, because sometimes you can actually drive quite closely to obstacles and service safe. And sometimes for some robot tasks, it's mandatory to drive close to obstacles. For the comfort, you could use the smoothness of the path as an indicator. Finally, we are not going into trajectory generation this semester. But remember that there are such physical things as velocity accelerations and the jerk, each being the derivative of the previous. And when you want to go from the the path that you planned to the actual directory, you now have to adapt it more closely to the to the actual vehicle physics and keep the impact of the explorations into drugs on the traffic participants in mind. With this, we have covered a lot of algorithms and principles that can be combined to perform autonomous parking to do adaptive cruise control to navigate around parking houses or cities. However, we have not really touched on traffic rules or complex interactions with our traffic participants. And this this field is very wide. There's a lot of material that you could study to, to go from here to the next step. For some reason, time also reinforcement learning has been very trendy in this domain. It's a deep learning method, where you have an agent learn policies to provide the best action to take depending on the current state of the vehicle. For each executed action, you provide an according reward to support the learning process and then you get A queue function that you approximate with a neural network in order to make the yeah and learn how to make the best choices of actions in given situations. This has some upsides and some downsides. And we can take a look at the video to explain this a little bit better. So here we are seeing an experiment of somebody's training vehicle with a reinforcement learning approach. And you'll see that first the car is not very knowledgeable about what it's supposed to do. So it

Transcribed by https://otter.ai
